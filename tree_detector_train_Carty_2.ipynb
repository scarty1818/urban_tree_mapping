{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jkubEgSxuX_",
        "outputId": "c4e8350d-8480-46ce-c6f4-604f3fa63073"
      },
      "id": "7jkubEgSxuX_",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet geopandas rasterio shapely fiona pyproj rtree ruamel.yaml\n",
        "!pip install arcgis --quiet"
      ],
      "metadata": {
        "id": "DUaw7R4pm3yZ"
      },
      "id": "DUaw7R4pm3yZ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from arcgis.gis import GIS\n",
        "from arcgis.features import FeatureLayer\n",
        "from arcgis.geometry import SpatialReference\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import uuid\n",
        "import glob\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, box as shp_box\n",
        "from shapely.ops import transform as shp_transform\n",
        "\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from rasterio.transform import Affine\n",
        "\n",
        "from ruamel.yaml import YAML\n",
        "\n",
        "# Optional: YOLOv8\n",
        "# pip install ultralytics\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    YOLO_AVAILABLE = True\n",
        "except Exception:\n",
        "    YOLO_AVAILABLE = False\n",
        "\n",
        "# Optional: DeepForest\n",
        "# pip install deepforest\n",
        "try:\n",
        "    from deepforest import main as deepforest_main\n",
        "    DEEPFOREST_AVAILABLE = True\n",
        "except Exception:\n",
        "    DEEPFOREST_AVAILABLE = False"
      ],
      "metadata": {
        "id": "s5OL_rgCHT6A"
      },
      "id": "s5OL_rgCHT6A",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f9519859",
      "metadata": {
        "id": "f9519859"
      },
      "outputs": [],
      "source": [
        "gis = GIS()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want anonymous access:\n",
        "# gis = GIS(anonymous=True)\n",
        "\n",
        "# Or with credentials (works in local Python 3.11 with Esri SDK; in Colab uses REST):\n",
        "gis = GIS(\"https://www.arcgis.com\", username=\"stefany.carty\", password=\"xyrMog-1jecbe-kegfif\")"
      ],
      "metadata": {
        "id": "08q7mPSVs6lo"
      },
      "id": "08q7mPSVs6lo",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b098408e",
      "metadata": {
        "id": "b098408e"
      },
      "outputs": [],
      "source": [
        "city_trees = r\"https://maps6.stlouis-mo.gov/arcgis/rest/services/FORESTRY/FORESTRY_TREES/MapServer/0\"\n",
        "forest_park_trees = r\"https://maps6.stlouis-mo.gov/arcgis/rest/services/FORESTRY/FORESTRY_TREES/MapServer/1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8d9d5a44",
      "metadata": {
        "id": "8d9d5a44"
      },
      "outputs": [],
      "source": [
        "class Config:  # Container for all configuration settings used across the pipeline\n",
        "    def __init__(self, name, overwrite=False):  # Initialize with a run name and whether to overwrite outputs\n",
        "        # Define run name\n",
        "        self.name = name  # Store the experiment/run name so outputs are grouped per run\n",
        "\n",
        "        # Input data\n",
        "        self.AERIAL_DIR = \"/content/drive/MyDrive/GIS/STL_TREES/chunk_732\"   # folder of GeoTIFFs (.tif) to tile and label\n",
        "        self.POINTS_PATH = \"https://maps6.stlouis-mo.gov/arcgis/rest/services/FORESTRY/FORESTRY_TREES/MapServer/0\"  # source of tree points (Esri Feature Service)\n",
        "\n",
        "        # Tiling\n",
        "        self.TILE_SIZE = 640            # pixels (YOLO-friendly) — 640×640 matches YOLOv8 default input size\n",
        "        self.TILE_OVERLAP = 0.2         # 20% overlap to avoid missing trees on tile edges and boost context for detection\n",
        "        self.MIN_VALID_PIXELS = 0.8     # discard tiles with >20% nodata — ensures model sees mostly real imagery\n",
        "        self.RGB_BANDS = (1,2,3)        # RGB band indices (1-based) in TIF — maps to raster bands used to render tiles\n",
        "\n",
        "        # Geo parameters\n",
        "        self.TARGET_MPP = None  # target meters-per-pixel for resampling (None = use raster native resolution)\n",
        "        self.POINT_BUFFER_M = 12.0  # approximate crown width (meters) used for circular/rectangular label width\n",
        "        self.SHADOW_LENGTH_M = 60.0  # total rectangle length (crown + shadow) for rectangular labels (meters)\n",
        "        self.SHADOW_ANGLE_DEG = -15.0  # default shadow direction (deg from north, clockwise) if not auto-estimated\n",
        "        self.USE_CIRCULAR_LABELS = False  # toggle between circular (buffer) vs rectangular (crown+shadow) labels\n",
        "        self.AUTO_DETECT_SHADOW = False  # if True, estimate dominant shadow angle from image edges/lines\n",
        "\n",
        "        # YOLO training\n",
        "        self.MODEL = \"yolov8n\"  # choose YOLOv8 variant (n = nano, fast/small; l/x = larger, slower, more accurate)\n",
        "        self.EPOCHS = 80  # number of training epochs (full passes over dataset)\n",
        "        self.BATCH = 16  # batch size per iteration (set based on GPU memory)\n",
        "        self.IMG_SIZE = 640  # image size given to YOLO (should match tile size for simplicity)\n",
        "\n",
        "        # Splits\n",
        "        self.VAL_RATIO = 0.2  # fraction of data used for validation (model tuning)\n",
        "        self.TEST_RATIO = 0.1  # fraction of data held out for final evaluation\n",
        "        self.SEED = 42  # random seed for reproducibility (same splits each run)\n",
        "\n",
        "        # Overwrite Outputs\n",
        "        self.OVERWRITE = overwrite  # if True, allow re-creating directories/files; else keep existing outputs\n",
        "\n",
        "        # Output\n",
        "        self.OUT_DIR = f\"/content/drive/MyDrive/GIS/STL_TREES/model_runs/{self.name}\"  # root folder for this run’s artifacts\n",
        "        self.TILES_DIR = os.path.join(self.OUT_DIR, \"tiles\")  # where image tiles (.jpg) will be saved\n",
        "        self.LABELS_DIR = os.path.join(self.OUT_DIR, \"labels\")  # where YOLO label files (.txt) will be saved\n",
        "        self.SPLITS_DIR = os.path.join(self.OUT_DIR, \"splits\")  # lists of train/val/test image paths\n",
        "        self.VIZ_DIR = os.path.join(self.OUT_DIR, \"visualizations\")  # quick-look images with boxes drawn for QA\n",
        "        self.METRICS_DIR = os.path.join(self.OUT_DIR, \"metrics\")  # place to store metrics, logs, curves\n",
        "        self.MODELS_DIR = os.path.join(self.OUT_DIR, \"models\")  # place where trained model weights/checkpoints go\n",
        "\n",
        "        self.ALL_DIRS = [  # convenient list of directories to create in one shot\n",
        "            self.OUT_DIR, self.TILES_DIR, self.LABELS_DIR,\n",
        "            self.SPLITS_DIR, self.VIZ_DIR, self.METRICS_DIR\n",
        "        ]\n",
        "\n",
        "        print(\"Initialization Successful.\")  # basic confirmation so the user knows config built correctly\n",
        "        self.initDirs()  # create all necessary directories (if not already present)\n",
        "\n",
        "    def initDirs(self):  # utility to create all directories in self.ALL_DIRS\n",
        "        _ = [os.makedirs(d, exist_ok=self.OVERWRITE) for d in self.ALL_DIRS]  # build each folder; allow overwrite based on flag\n",
        "\n",
        "    def writeExperiment(self):\n",
        "        df = pd.DataFrame([vars])\n",
        "\n",
        "\n",
        "    def initChecks(self):  # verify that model directory and expected model name exist before training\n",
        "        if os.path.exists(self.MODELS_DIR):  # confirm models root exists\n",
        "            pass  # nothing to do — existence is enough\n",
        "        else:\n",
        "            raise Exception(\"Error: Model directory does not exist.\")  # fail early to avoid confusing downstream errors\n",
        "\n",
        "        if os.path.exists(os.path.join(self.METRICS_DIR, self.MODEL)):  # check presence of a subfolder named after the model\n",
        "            pass  # OK — found expected model subfolder\n",
        "        else:\n",
        "            raise Exception(f\"Model {self.MODEL} is missing in the models folder\")  # alert user to misconfiguration\n",
        "\n",
        "        print(\"Model found. Creating output folders.\")  # status message before building folders\n",
        "        self.initDirs()  # create remaining output folders if needed\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 1) UTILITIES\n",
        "# -------------------------------\n",
        "\n",
        "def list_tifs(folder: str) -> list[str]:  # return sorted list of all .tif files in a folder\n",
        "    return sorted(glob.glob(os.path.join(folder, \"*.tif\")))  # use glob to find GeoTIFFs and sort for deterministic order\n",
        "\n",
        "def load_points(points_path: str, target_crs=4326) -> gpd.GeoDataFrame:  # load tree points from URL or file, project to target CRS\n",
        "    ## IF it is an Esri Feature Service or Web Map\n",
        "    if \"HTTPS\" in points_path.upper():  # simple heuristic: treat HTTPS path as a web feature service URL\n",
        "        gis_query = FeatureLayer(points_path).query(where=\"1=1\", out_sr=target_crs.to_wkt())  # query all features and request target spatial ref\n",
        "        attributes = [dict(x.attributes, LAT = x.geometry['y'], LON = x.geometry['x']) for x in gis_query.features]  # flatten attributes and add XY\n",
        "        df = pd.DataFrame(attributes)  # convert to pandas DataFrame for easy manipulation\n",
        "        gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.LON, df.LAT), crs = target_crs.to_wkt())  # build GeoDataFrame with correct CRS\n",
        "        gdf.head()  # no-op preview in notebooks; safe even if not used programmatically\n",
        "\n",
        "    else:  # else treat as a local file (e.g., shapefile/geojson)\n",
        "        gdf = gpd.read_file(points_path)  # read geospatial file from disk into GeoDataFrame\n",
        "        if gdf.crs is None:  # ensure the dataset has a defined CRS\n",
        "            raise ValueError(\"Point dataset lacks a CRS; assign the correct CRS before running.\")  # fail early if CRS is missing\n",
        "        if target_crs and gdf.crs != target_crs:  # if target CRS requested and different from current\n",
        "            gdf = gdf.to_crs(target_crs)  # reproject to target CRS for consistent math with rasters\n",
        "\n",
        "    return gdf  # return GeoDataFrame of points in the requested CRS\n",
        "\n",
        "def read_geotiff_rgb(path: str, bands=(1,2,3)) -> tuple[np.ndarray, dict]:  # read a GeoTIFF and return RGB image + metadata\n",
        "    with rasterio.open(path) as src:  # open the raster safely using context manager\n",
        "        count = src.count  # number of bands available in the file\n",
        "        if count == 1:  # handle single-band grayscale imagery\n",
        "            img = src.read(1)  # read the single band\n",
        "            img = np.stack([img, img, img], axis=2)  # replicate into 3 channels to make pseudo-RGB\n",
        "        else:\n",
        "            b = [i for i in bands if i <= count]  # clip requested bands to what exists in the file\n",
        "            img = src.read(b)  # read selected bands as (C, H, W)\n",
        "            img = np.transpose(img, (1,2,0))  # HWC  # rearrange to height×width×channels for OpenCV/PIL\n",
        "        meta = {  # capture necessary geospatial metadata for later transformations\n",
        "            \"crs\": src.crs,  # coordinate reference system\n",
        "            \"transform\": src.transform,  # affine transform from pixel to map coords\n",
        "            \"width\": src.width,  # raster width in pixels\n",
        "            \"height\": src.height,  # raster height in pixels\n",
        "            \"res\": src.res,  # pixel size in map units (xres, yres)\n",
        "            \"nodata\": src.nodata  # nodata value if defined, else None\n",
        "        }\n",
        "    # Normalize to uint8 if not already\n",
        "    if img.dtype != np.uint8:  # many GeoTIFFs are 16-bit/float — convert to 8-bit for visualization/YOLO\n",
        "        imin, imax = np.nanmin(img), np.nanmax(img)  # find min and max ignoring NaNs\n",
        "        if imax > imin:  # avoid division by zero if image is constant\n",
        "            img = ((img - imin) / (imax - imin) * 255.0).clip(0,255).astype(np.uint8)  # scale to [0,255] and cast to uint8\n",
        "        else:\n",
        "            img = np.zeros_like(img, dtype=np.uint8)  # if flat image, return a black image to keep shape consistent\n",
        "    return img, meta  # return ready-to-tile RGB array and associated geospatial metadata\n",
        "\n",
        "def tile_indices(width: int, height: int, tile: int, overlap: float):  # generator yielding (x,y) pixel offsets for tiles with overlap\n",
        "    step = int(tile * (1.0 - overlap))  # stride between tiles based on overlap fraction\n",
        "    ys = list(range(0, max(1, height - tile + 1), step))  # starting y positions for tiles\n",
        "    xs = list(range(0, max(1, width - tile + 1), step))  # starting x positions for tiles\n",
        "    if ys[-1] + tile < height:  # if last tile doesn't touch bottom edge\n",
        "        ys.append(height - tile)  # add final row anchored to bottom\n",
        "    if xs[-1] + tile < width:  # if last tile doesn't touch right edge\n",
        "        xs.append(width - tile)  # add final column anchored to right\n",
        "    for y in ys:  # iterate all y starts\n",
        "        for x in xs:  # iterate all x starts\n",
        "            yield x, y  # produce top-left pixel for this tile\n",
        "\n",
        "def compute_tile_bounds(transform: Affine, x0: int, y0: int, tile: int) -> tuple[float,float,float,float]:  # map pixel tile to geographic bbox\n",
        "    # Rasterio affine: x_geo = a*x + b*y + c ; y_geo = d*x + e*y + f\n",
        "    # Typically b=d=0; a=resx; e=-resy\n",
        "    x_left, y_top = transform * (x0, y0)  # transform tile’s top-left pixel to map coordinates\n",
        "    x_right, y_bottom = transform * (x0 + tile, y0 + tile)  # transform bottom-right pixel of tile to map coordinates\n",
        "    xmin, xmax = min(x_left, x_right), max(x_left, x_right)  # normalize x min/max in case of negative pixel size\n",
        "    ymin, ymax = min(y_bottom, y_top), max(y_bottom, y_top)  # normalize y min/max (note y axis may be inverted)\n",
        "    return xmin, ymin, xmax, ymax  # return geographic bounding box of the tile\n",
        "\n",
        "def yolo_bbox_from_geo_circle(pt: Point, radius_m: float, transform: Affine, tile_bounds: tuple[float,float,float,float], tile_size: int):  # make YOLO box from a circle buffer\n",
        "    xmin, ymin, xmax, ymax = tile_bounds  # unpack geographic tile bounds\n",
        "    cx, cy = pt.x, pt.y  # center point of tree in map units\n",
        "    # clamp circle to tile bbox\n",
        "    bxmin = max(xmin, cx - radius_m)  # clamp left\n",
        "    bymin = max(ymin, cy - radius_m)  # clamp bottom\n",
        "    bxmax = min(xmax, cx + radius_m)  # clamp right\n",
        "    bymax = min(ymax, cy + radius_m)  # clamp top\n",
        "    if bxmin >= bxmax or bymin >= bymax:  # if circle doesn’t intersect tile\n",
        "        return None  # no label for this tile\n",
        "\n",
        "    # Convert geo -> pixel within tile coordinates\n",
        "    # inverse affine\n",
        "    inv = ~transform  # invert transform to go from map coords to pixel coords\n",
        "    # Tile origin (x0, y0) in pixels\n",
        "    x0_pix, y0_pix = inv * (xmin, ymax)  # note ymax used for y due to affine sign  # compute tile’s pixel origin\n",
        "    # Corners in pixels in full image coords\n",
        "    xmin_pix, ymin_pix = inv * (bxmin, bymin)  # convert clamped bbox min to pixel\n",
        "    xmax_pix, ymax_pix = inv * (bxmax, bymax)  # convert clamped bbox max to pixel\n",
        "    # Convert to tile-local pixel coords\n",
        "    x_min_local = xmin_pix - x0_pix  # shift to tile’s local x origin\n",
        "    x_max_local = xmax_pix - x0_pix  # shift to tile’s local x origin\n",
        "    y_min_local = ymax_pix - y0_pix  # note y inversion  # adjust for raster coordinate direction\n",
        "    y_max_local = ymin_pix - y0_pix  # adjust for raster coordinate direction\n",
        "\n",
        "    # Clamp to tile size\n",
        "    x_min_local = np.clip(x_min_local, 0, tile_size)  # keep inside tile bounds\n",
        "    x_max_local = np.clip(x_max_local, 0, tile_size)  # keep inside tile bounds\n",
        "    y_min_local = np.clip(y_min_local, 0, tile_size)  # keep inside tile bounds\n",
        "    y_max_local = np.clip(y_max_local, 0, tile_size)  # keep inside tile bounds\n",
        "\n",
        "    if x_max_local - x_min_local <= 1 or y_max_local - y_min_local <= 1:  # ignore boxes that are basically zero-sized\n",
        "        return None  # too small to be useful\n",
        "\n",
        "    # Convert to YOLO normalized cx, cy, w, h in [0,1]\n",
        "    cx_local = (x_min_local + x_max_local) / 2.0  # center x in pixels\n",
        "    cy_local = (y_min_local + y_max_local) / 2.0  # center y in pixels\n",
        "    w_local = (x_max_local - x_min_local)  # width in pixels\n",
        "    h_local = (y_max_local - y_min_local)  # height in pixels\n",
        "\n",
        "    return (\n",
        "        (cx_local / tile_size),  # normalize center x to [0,1]\n",
        "        (cy_local / tile_size),  # normalize center y to [0,1]\n",
        "        (w_local / tile_size),   # normalize width to [0,1]\n",
        "        (h_local / tile_size)    # normalize height to [0,1]\n",
        "    )\n",
        "\n",
        "def yolo_bbox_from_geo_rectangle(pt: Point, crown_width_m: float, shadow_length_m: float,\n",
        "                                shadow_angle_deg: float, transform: Affine,\n",
        "                                tile_bounds: tuple[float,float,float,float], tile_size: int):  # make YOLO box from oriented rectangle (crown+shadow)\n",
        "    \"\"\"\n",
        "    Create rectangular bounding box for tree with shadow\n",
        "\n",
        "    Args:\n",
        "        pt: Tree point location\n",
        "        crown_width_m: Crown width (perpendicular to shadow)\n",
        "        shadow_length_m: Total length including shadow\n",
        "        shadow_angle_deg: Shadow direction (degrees from north, clockwise)\n",
        "        transform: Rasterio transform\n",
        "        tile_bounds: Tile geographic bounds\n",
        "        tile_size: Tile size in pixels\n",
        "\n",
        "    Returns:\n",
        "        YOLO format bbox (cx, cy, w, h) normalized [0,1] or None\n",
        "    \"\"\"\n",
        "    import math  # local import to keep function self-contained\n",
        "\n",
        "    xmin, ymin, xmax, ymax = tile_bounds  # unpack tile bounds in map coordinates\n",
        "    cx, cy = pt.x, pt.y  # center at tree point location (map units)\n",
        "\n",
        "    # Convert angle to radians (0° = North, clockwise positive)\n",
        "    angle_rad = math.radians(shadow_angle_deg)  # convert degrees to radians for trig\n",
        "\n",
        "    # Calculate rectangle corners\n",
        "    # Half dimensions\n",
        "    half_width = crown_width_m / 2.0  # half of rectangle width (across shadow)\n",
        "    half_length = shadow_length_m / 2.0  # half of rectangle length (along shadow)\n",
        "\n",
        "    # Rectangle corners in local coordinate system (before rotation)\n",
        "    corners_local = [\n",
        "        (-half_width, -half_length),  # Bottom-left relative to center\n",
        "        (half_width, -half_length),   # Bottom-right relative to center\n",
        "        (half_width, half_length),    # Top-right relative to center\n",
        "        (-half_width, half_length)    # Top-left relative to center\n",
        "    ]\n",
        "\n",
        "    # Rotate corners around center point\n",
        "    cos_a = math.cos(angle_rad)  # precompute cosine for rotation\n",
        "    sin_a = math.sin(angle_rad)  # precompute sine for rotation\n",
        "\n",
        "    corners_geo = []  # will hold rotated corners in map coordinates\n",
        "    for x_local, y_local in corners_local:  # rotate each local corner around the center\n",
        "        # Rotate point\n",
        "        x_rot = x_local * cos_a - y_local * sin_a  # x rotation formula\n",
        "        y_rot = x_local * sin_a + y_local * cos_a  # y rotation formula\n",
        "\n",
        "        # Translate to world coordinates\n",
        "        x_world = cx + x_rot  # shift rotated x to map x\n",
        "        y_world = cy + y_rot  # shift rotated y to map y\n",
        "        corners_geo.append((x_world, y_world))  # collect rotated corner\n",
        "\n",
        "    # Find bounding box of rotated rectangle\n",
        "    x_coords = [c[0] for c in corners_geo]  # list of x coords\n",
        "    y_coords = [c[1] for c in corners_geo]  # list of y coords\n",
        "\n",
        "    bbox_xmin = max(min(x_coords), xmin)  # clamp bbox to tile left\n",
        "    bbox_xmax = min(max(x_coords), xmax)  # clamp bbox to tile right\n",
        "    bbox_ymin = max(min(y_coords), ymin)  # clamp bbox to tile bottom\n",
        "    bbox_ymax = min(max(y_coords), ymax)  # clamp bbox to tile top\n",
        "\n",
        "    # Check if bbox is within tile bounds\n",
        "    if bbox_xmin >= bbox_xmax or bbox_ymin >= bbox_ymax:  # if box is empty after clamping\n",
        "        return None  # nothing to label\n",
        "\n",
        "    # Convert to pixel coordinates\n",
        "    inv_transform = ~transform  # invert affine to map → pixel\n",
        "\n",
        "    # Convert bbox corners to pixels\n",
        "    xmin_pix, ymin_pix = inv_transform * (bbox_xmin, bbox_ymin)  # min corner in pixels\n",
        "    xmax_pix, ymax_pix = inv_transform * (bbox_xmax, bbox_ymax)  # max corner in pixels\n",
        "\n",
        "    # Convert to tile-local coordinates\n",
        "    tile_x0, tile_y0 = inv_transform * (xmin, ymax)  # Tile origin  # get pixel origin for this tile\n",
        "\n",
        "    x_min_local = xmin_pix - tile_x0  # shift to tile coordinates (x min)\n",
        "    x_max_local = xmax_pix - tile_x0  # shift to tile coordinates (x max)\n",
        "    y_min_local = ymax_pix - tile_y0  # Note: y-axis flip  # adjust for raster y direction\n",
        "    y_max_local = ymin_pix - tile_y0  # adjust for raster y direction\n",
        "\n",
        "    # Ensure correct ordering\n",
        "    if x_min_local > x_max_local:  # if swapped due to transform peculiarities\n",
        "        x_min_local, x_max_local = x_max_local, x_min_local  # swap so min < max\n",
        "    if y_min_local > y_max_local:  # if swapped due to y inversion\n",
        "        y_min_local, y_max_local = y_max_local, y_min_local  # swap so min < max\n",
        "\n",
        "    # Clamp to tile size\n",
        "    x_min_local = max(0, min(x_min_local, tile_size))  # clamp to [0, tile_size]\n",
        "    x_max_local = max(0, min(x_max_local, tile_size))  # clamp to [0, tile_size]\n",
        "    y_min_local = max(0, min(y_min_local, tile_size))  # clamp to [0, tile_size]\n",
        "    y_max_local = max(0, min(y_max_local, tile_size))  # clamp to [0, tile_size]\n",
        "\n",
        "    # Check minimum size\n",
        "    if x_max_local - x_min_local <= 2 or y_max_local - y_min_local <= 2:  # avoid tiny boxes that don’t help training\n",
        "        return None  # skip unusable boxes\n",
        "\n",
        "    # Convert to YOLO format (center_x, center_y, width, height) normalized [0,1]\n",
        "    center_x = (x_min_local + x_max_local) / 2.0 / tile_size  # normalize center x\n",
        "    center_y = (y_min_local + y_max_local) / 2.0 / tile_size  # normalize center y\n",
        "    width = (x_max_local - x_min_local) / tile_size  # normalize width\n",
        "    height = (y_max_local - y_max_local + y_min_local) / tile_size if False else (y_max_local - y_min_local) / tile_size  # normalize height (explicit to show intent)\n",
        "\n",
        "    return (center_x, center_y, width, height)  # final YOLO box tuple\n",
        "\n",
        "def estimate_shadow_angle_from_image(image: np.ndarray, tree_points: list) -> float:  # estimate dominant shadow direction from edges/lines\n",
        "    \"\"\"\n",
        "    Estimate shadow direction from image analysis\n",
        "\n",
        "    Args:\n",
        "        image: RGB image array\n",
        "        tree_points: List of tree point locations in pixel coordinates\n",
        "\n",
        "    Returns:\n",
        "        Shadow angle in degrees from north (clockwise)\n",
        "    \"\"\"\n",
        "    import cv2  # use OpenCV for edge detection and Hough transform\n",
        "    from scipy import ndimage  # available for additional filtering if needed\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # shadows pop more clearly in grayscale\n",
        "\n",
        "    # Apply edge detection to find shadow edges\n",
        "    edges = cv2.Canny(gray, 50, 150)  # Canny emphasizes edges that Hough uses to detect lines\n",
        "\n",
        "    # Find lines using Hough transform\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)  # detect straight lines and their angles\n",
        "\n",
        "    if lines is not None:  # if we detected any candidate lines\n",
        "        # Analyze line angles\n",
        "        angles = []  # will collect each line’s angle\n",
        "        for rho, theta in lines[:, 0]:  # iterate Hough results\n",
        "            angle_deg = np.degrees(theta) - 90  # Convert to standard angle (0 = vertical) to align with “from north”\n",
        "            angles.append(angle_deg)  # store for histogram analysis\n",
        "\n",
        "        # Find most common angle (shadow direction)\n",
        "        angles = np.array(angles)  # numpy array for efficient histogramming\n",
        "\n",
        "        # Use histogram to find dominant angle\n",
        "        hist, bins = np.histogram(angles, bins=36, range=(-180, 180))  # coarse binning to get dominant orientation\n",
        "        dominant_angle_idx = np.argmax(hist)  # pick bin with most votes\n",
        "        shadow_angle = (bins[dominant_angle_idx] + bins[dominant_angle_idx + 1]) / 2  # center of dominant bin\n",
        "\n",
        "        return shadow_angle % 360  # normalize to [0, 360)\n",
        "\n",
        "    # Default angle if detection fails\n",
        "    return 45.0  # Assume northeast shadow directio  # fallback that still produces rectangular labels\n",
        "\n",
        "def estimate_tile_nodata_fraction(img: np.ndarray, nodata: Optional[float]) -> float:  # compute proportion of nodata pixels in a tile\n",
        "    if nodata is None:  # if raster has no nodata defined, assume fully valid\n",
        "        return 0.0  # zero nodata fraction\n",
        "    mask = (img[:,:,0] == nodata) & (img[:,:,1] == nodata) & (img[:,:,2] == nodata)  # treat pixel as nodata only if all channels equal nodata\n",
        "    return float(mask.mean())  # return fraction of nodata pixels as a float\n",
        "\n",
        "def draw_yolo_boxes_on_image(image: np.ndarray, labels_file: str, color=(0,255,0)) -> np.ndarray:  # overlay YOLO txt boxes onto an image (for QA)\n",
        "    h, w = image.shape[:2]  # get image height and width\n",
        "    if not os.path.exists(labels_file):  # if there is no label file for this tile\n",
        "        return image  # return the image unchanged\n",
        "    out = image.copy()  # copy so we don’t modify the input array\n",
        "    with open(labels_file, \"r\") as f:  # open YOLO label file\n",
        "        for line in f:  # parse each label line\n",
        "            parts = line.strip().split()  # split by whitespace\n",
        "            if len(parts) < 5:  # ensure line has class + 4 box values\n",
        "                continue  # skip malformed lines\n",
        "            _, cx, cy, bw, bh = map(float, parts[:5])  # YOLO format: class cx cy w h (normalized)\n",
        "            cxp, cyp = int(cx * w), int(cy * h)  # denormalize center to pixel coords\n",
        "            wp, hp = int(bw * w), int(bh * h)  # denormalize width/height to pixels\n",
        "            x1, y1 = int(cxp - wp/2), int(cyp - hp/2)  # compute top-left pixel\n",
        "            x2, y2 = x1 + wp, y1 + hp  # compute bottom-right pixel\n",
        "            cv2.rectangle(out, (x1,y1), (x2,y2), color, 2)  # draw rectangle for the label\n",
        "    return out  # return image with boxes rendered\n",
        "\n",
        "# -------------------------------\n",
        "# 2) PIPELINE: TILING + PSEUDO-LABELS FROM POINTS\n",
        "# -------------------------------\n",
        "\n",
        "def process_imagery_and_generate_labels(cfg):  # master function: tile rasters and create YOLO label files from point data\n",
        "    \"\"\"\n",
        "    Updated processing function with rectangular bounding boxes\n",
        "    \"\"\"\n",
        "    tif_paths = list_tifs(cfg.AERIAL_DIR)  # gather all GeoTIFFs from the input directory\n",
        "    if not tif_paths:  # if no imagery found, fail loudly with a clear message\n",
        "        raise FileNotFoundError(f\"No .tif found in {cfg.AERIAL_DIR}\")  # help user fix paths\n",
        "\n",
        "    label_count = 0  # running total of labels created\n",
        "    tile_count = 0  # running total of tiles generated\n",
        "    yolo_items = []  # list of (image_path, label_path) for later splitting\n",
        "\n",
        "    for tif in tif_paths:  # process each image one by one\n",
        "        img, meta = read_geotiff_rgb(tif, bands=cfg.RGB_BANDS)  # read RGB array and metadata for this raster\n",
        "        transform = meta[\"transform\"]  # affine used to convert between pixels and map coords\n",
        "        crs = meta[\"crs\"]  # coordinate reference system of the raster\n",
        "\n",
        "        # Load points in the image CRS\n",
        "        points_gdf = load_points(cfg.POINTS_PATH, crs)  # fetch trees points and project to raster CRS for accurate geometry tests\n",
        "\n",
        "        # Estimate shadow angle if auto-detection is enabled\n",
        "        shadow_angle = cfg.SHADOW_ANGLE_DEG  # start with default shadow angle\n",
        "        if cfg.AUTO_DETECT_SHADOW:  # only compute if user requested\n",
        "            # Convert some tree points to pixel coordinates for shadow analysis\n",
        "            tree_pixels = []  # will store point locations in pixel space\n",
        "            inv_transform = ~transform  # invert transform for map→pixel conversion\n",
        "            for idx, row in points_gdf.iterrows():  # iterate over points\n",
        "                if not row.geometry or row.geometry.is_empty:  # skip invalid geometries\n",
        "                        continue  # move on if no usable geometry\n",
        "                # Get coordinates\n",
        "                x_coord = row.geometry.x  # map x of tree\n",
        "                y_coord = row.geometry.y  # map y of tree\n",
        "\n",
        "                if np.isnan(x_coord) or np.isnan(y_coord):  # guard against NaN coords\n",
        "                    print(f\"Warning: NaN coordinates found in point {idx}: ({x_coord}, {y_coord})\")  # warn but continue\n",
        "                    continue  # skip bad point\n",
        "\n",
        "                px, py = inv_transform * (x_coord, y_coord)  # convert to pixel coordinates\n",
        "                tree_pixels.append((int(px), int(py)))  # keep integer pixel positions for analysis\n",
        "\n",
        "                if np.isnan(px) or np.isnan(py):  # extra guard after conversion\n",
        "                    print(f\"Warning: NaN in transformed coordinates: ({px}, {py})\")  # warn if conversion failed oddly\n",
        "                    continue  # skip if invalid\n",
        "\n",
        "            if tree_pixels:  # only attempt estimation if we have some points\n",
        "                estimated_angle = estimate_shadow_angle_from_image(img, tree_pixels)  # detect dominant line angle\n",
        "                shadow_angle = estimated_angle  # use the estimated angle for rectangular labels\n",
        "                print(f\"Estimated shadow angle: {shadow_angle:.1f}°\")  # show value for transparency\n",
        "\n",
        "        H, W = img.shape[:2]  # image height and width in pixels\n",
        "        for x0, y0 in tile_indices(W, H, cfg.TILE_SIZE, cfg.TILE_OVERLAP):  # loop over all tile start positions\n",
        "            tile = img[y0:y0+cfg.TILE_SIZE, x0:x0+cfg.TILE_SIZE, :]  # crop tile from full image\n",
        "            if tile.shape[0] < cfg.TILE_SIZE or tile.shape[1] < cfg.TILE_SIZE:  # skip partial tiles at borders\n",
        "                continue  # only keep exact-size tiles\n",
        "\n",
        "            # Compute tile bounds in geo coords\n",
        "            xmin, ymin, xmax, ymax = compute_tile_bounds(transform, x0, y0, cfg.TILE_SIZE)  # geographic extent of this tile\n",
        "            tile_poly = shp_box(xmin, ymin, xmax, ymax)  # shapely polygon for fast point-in-polygon tests\n",
        "\n",
        "            # Skip nodata-heavy tiles\n",
        "            nodata_frac = estimate_tile_nodata_fraction(tile, meta[\"nodata\"])  # measure how much nodata this tile has\n",
        "            if nodata_frac > (1 - cfg.MIN_VALID_PIXELS):  # if too much nodata, this tile is low quality\n",
        "                continue  # skip to keep dataset clean\n",
        "\n",
        "            # Filter points inside tile bounds\n",
        "            pts_in = points_gdf[points_gdf.geometry.within(tile_poly)]  # select only trees that fall inside this tile\n",
        "\n",
        "            # Build YOLO labels\n",
        "            labels = []  # will store YOLO strings (class cx cy w h)\n",
        "            for _, row in pts_in.iterrows():  # for each tree in the tile\n",
        "                pt: Point = row.geometry  # get the shapely point\n",
        "\n",
        "                if cfg.USE_CIRCULAR_LABELS:  # choose circular (buffer) style boxes\n",
        "                    # Use original circular approach\n",
        "                    yolo_box = yolo_bbox_from_geo_circle(\n",
        "                        pt=pt,  # tree location\n",
        "                        radius_m=cfg.POINT_BUFFER_M,  # circular radius ~crown width/2\n",
        "                        transform=transform,  # affine to convert geo→pixel\n",
        "                        tile_bounds=(xmin, ymin, xmax, ymax),  # geographic bounds of current tile\n",
        "                        tile_size=cfg.TILE_SIZE  # size of tile in pixels for normalization\n",
        "                    )\n",
        "                else:  # choose rectangular (crown+shadow) style boxes\n",
        "                    # Use new rectangular approach\n",
        "                    yolo_box = yolo_bbox_from_geo_rectangle(\n",
        "                        pt=pt,  # tree location\n",
        "                        crown_width_m=cfg.POINT_BUFFER_M,  # rectangle width across shadow direction\n",
        "                        shadow_length_m=cfg.SHADOW_LENGTH_M,  # rectangle length along shadow direction\n",
        "                        shadow_angle_deg=shadow_angle,  # orientation of the rectangle\n",
        "                        transform=transform,  # affine for geo→pixel\n",
        "                        tile_bounds=(xmin, ymin, xmax, ymax),  # geographic tile bbox\n",
        "                        tile_size=cfg.TILE_SIZE  # used to normalize to YOLO space\n",
        "                    )\n",
        "\n",
        "                if yolo_box is None:  # skip trees that couldn’t form a valid box (e.g., off-edge)\n",
        "                    continue  # move to next point\n",
        "\n",
        "                cx, cy, w, h = yolo_box  # unpack YOLO-format values\n",
        "                if w <= 0 or h <= 0:  # ensure positive box dimensions\n",
        "                    continue  # skip non-sensical boxes\n",
        "\n",
        "                labels.append(f\"0 {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\")  # write class 0 (tree) with normalized box values\n",
        "\n",
        "            # Save tile and labels\n",
        "            base = f\"{Path(tif).stem}_{x0}_{y0}\"  # create a unique basename per tile using raster name and tile offset\n",
        "            img_out = os.path.join(cfg.TILES_DIR, base + \".jpg\")  # output path for the tile image\n",
        "            lbl_out = os.path.join(cfg.LABELS_DIR, base + \".txt\")  # output path for the label file\n",
        "\n",
        "            Image.fromarray(tile).save(img_out, quality=95)  # save the tile as a JPEG for YOLO\n",
        "            with open(lbl_out, \"w\") as f:  # write labels to text file\n",
        "                f.write(\"\\n\".join(labels))  # one YOLO line per detected tree\n",
        "\n",
        "            yolo_items.append((img_out, lbl_out))  # remember pairing for dataset splitting\n",
        "            tile_count += 1  # increment number of tiles created\n",
        "            label_count += len(labels)  # accumulate number of labels generated\n",
        "\n",
        "    print(f\"Tiled images: {tile_count}, rectangular labels: {label_count}\")  # quick summary of how much was produced\n",
        "    return yolo_items  # return list of (image_path, label_path) to feed the splitter\n",
        "\n",
        "# -------------------------------\n",
        "# 3) DATA SPLIT\n",
        "# -------------------------------\n",
        "\n",
        "def split_data(yolo_items: List[tuple[str,str]], cfg):  # split (img,label) pairs into train/val/test lists\n",
        "    rng = np.random.default_rng(cfg.SEED)  # seeded RNG for reproducible shuffling\n",
        "    items = np.array(yolo_items, dtype=object)  # convert to numpy array for easy shuffling/slicing\n",
        "    rng.shuffle(items)  # shuffle in place to randomize order\n",
        "\n",
        "    n = len(items)  # total number of samples\n",
        "    n_test = int(n * cfg.TEST_RATIO)  # size of test set\n",
        "    n_val = int(n * cfg.VAL_RATIO)  # size of validation set\n",
        "    n_train = n - n_val - n_test  # remaining goes to training\n",
        "\n",
        "    train, val, test = items[:n_train], items[n_train:n_train+n_val], items[n_train+n_val:]  # slice into splits\n",
        "\n",
        "    # Save split lists\n",
        "    def save_split(split, name):  # helper to write list of image paths to a text file\n",
        "        img_list = [i[0] for i in split]  # only save image paths (YOLO finds labels by stem)\n",
        "        with open(os.path.join(cfg.SPLITS_DIR, f\"{name}.txt\"), \"w\") as f:  # open split file for writing\n",
        "            f.write(\"\\n\".join(img_list))  # write one path per line\n",
        "\n",
        "    save_split(train, \"train\")  # write train.txt\n",
        "    save_split(val, \"val\")  # write val.txt\n",
        "    save_split(test, \"test\")  # write test.txt\n",
        "\n",
        "    print(f\"Split: train={len(train)}, val={len(val)}, test={len(test)}\")  # report split sizes for sanity\n",
        "    return train, val, test  # return split arrays (each element is (img_path, label_path))\n",
        "\n",
        "def restructure_splits_for_yolo(cfg, train_list, val_list, test_list):  # copy/symlink split files into YOLO folder structure\n",
        "    \"\"\"\n",
        "    Restructure dataset to YOLO format using split lists from split_data()\n",
        "\n",
        "    Args:\n",
        "        cfg: Configuration object\n",
        "        train_list: List of tuples (image_path, label_path) from split_data()\n",
        "        val_list: List of tuples (image_path, label_path) from split_data()\n",
        "        test_list: List of tuples (image_path, label_path) from split_data()\n",
        "\n",
        "    Returns:\n",
        "        yolo_root: Path to restructured YOLO dataset\n",
        "    \"\"\"\n",
        "    import shutil  # copying files across directories\n",
        "    from pathlib import Path  # robust path handling\n",
        "\n",
        "    # Create YOLO structure\n",
        "    yolo_root = cfg.OUT_DIR  # use run’s OUT_DIR as the YOLO dataset root\n",
        "    for split in ['train', 'val', 'test']:  # make images/labels directories for each split\n",
        "        os.makedirs(os.path.join(yolo_root, 'images', split), exist_ok=cfg.OVERWRITE)  # ensure images split dir exists\n",
        "        os.makedirs(os.path.join(yolo_root, 'labels', split), exist_ok=cfg.OVERWRITE)  # ensure labels split dir exists\n",
        "\n",
        "    # Process each split\n",
        "    splits_data = {  # map split name to its list\n",
        "        'train': train_list,\n",
        "        'val': val_list,\n",
        "        'test': test_list\n",
        "    }\n",
        "\n",
        "    stats = {'train': 0, 'val': 0, 'test': 0}  # track how many images actually have labels\n",
        "\n",
        "    for split_name, split_items in splits_data.items():  # iterate over each split\n",
        "        print(f\"Processing {split_name} split: {len(split_items)} items...\")  # progress message\n",
        "\n",
        "        for img_path, label_path in split_items:  # for each (image, label) pair\n",
        "            if not os.path.exists(img_path):  # guard against missing images\n",
        "                print(f\"Warning: Image not found: {img_path}\")  # warn and skip\n",
        "                continue  # move to next item\n",
        "\n",
        "            # Get file names\n",
        "            img_name = Path(img_path).name  # extract just the image file name\n",
        "            label_name = Path(img_path).stem + '.txt'  # label file name must match image stem\n",
        "\n",
        "            # Destination paths\n",
        "            dst_img = os.path.join(yolo_root, 'images', split_name, img_name)  # where the image should live in YOLO tree\n",
        "            dst_label = os.path.join(yolo_root, 'labels', split_name, label_name)  # where the label should live\n",
        "\n",
        "            # Copy image\n",
        "            try:\n",
        "                shutil.copy2(img_path, dst_img)  # copy with metadata preserved\n",
        "            except Exception as e:\n",
        "                print(f\"Error copying image {img_path}: {e}\")  # report copy issues\n",
        "                continue  # skip if we can’t copy\n",
        "\n",
        "            # Copy label (if exists and has content)\n",
        "            if os.path.exists(label_path):  # if the label file exists\n",
        "                try:\n",
        "                    with open(label_path, 'r') as f:  # read the label\n",
        "                        label_content = f.read().strip()  # trim whitespace to see if it’s empty\n",
        "\n",
        "                    if label_content:  # if the label has at least one bbox\n",
        "                        # Copy non-empty label\n",
        "                        shutil.copy2(label_path, dst_label)  # copy label beside image\n",
        "                        stats[split_name] += 1  # count as labeled\n",
        "                    else:\n",
        "                        # Create empty label file for negative examples\n",
        "                        open(dst_label, 'w').close()  # empty txt still valid — tells YOLO “no objects”\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing label {label_path}: {e}\")  # show why label failed\n",
        "                    # Create empty label file as fallback\n",
        "                    open(dst_label, 'w').close()  # still create an empty label so the image is included\n",
        "            else:\n",
        "                # Create empty label file for missing labels\n",
        "                open(dst_label, 'w').close()  # negative example: no boxes in this image\n",
        "                print(f\"Warning: No label file found for {img_path}\")  # notify about missing label\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"\\n=== YOLO Dataset Creation Summary ===\")  # section header for clarity\n",
        "    print(f\"Dataset root: {yolo_root}\")  # remind path where dataset lives\n",
        "    for split_name, count in stats.items():  # report per split\n",
        "        total_imgs = len(splits_data[split_name])  # total images in this split\n",
        "        print(f\"{split_name.capitalize()}: {total_imgs} images, {count} with labels ({count/total_imgs*100:.1f}%)\")  # percent labeled\n",
        "\n",
        "# -------------------------------\n",
        "# 4) YOLO DATA.YAML AND TRAIN\n",
        "# -------------------------------\n",
        "\n",
        "def write_yolo_data_yaml(cfg):  # create a minimal data.yaml that points YOLO to images/labels\n",
        "    yaml_path = os.path.join(cfg.OUT_DIR, f\"{cfg.name}.yaml\")  # name the YAML after the run for clarity\n",
        "\n",
        "    ## Initialize YAML\n",
        "    yaml = YAML()  # ruamel YAML instance for robust dumping\n",
        "\n",
        "    yaml.preserve_quotes = True  # keep any quotes if present (style preference)\n",
        "\n",
        "    data_config = {  # structure expected by Ultralytics YOLO\n",
        "    'path': os.path.abspath(cfg.OUT_DIR),  # Absolute path to your dataset root  # ensures YOLO can resolve relative dirs\n",
        "    'train': 'images/train',  # Relative path to training images from 'path'  # keeps file tree portable\n",
        "    'val': 'images/val',      # Relative path to validation images from 'path'  # standard YOLO layout\n",
        "    'test': 'images/test',    # Relative path to test images from 'path' (optional)  # included for completeness\n",
        "    'names': {0: 'tree'}  # class index mapping — single class “tree”\n",
        "    }\n",
        "\n",
        "    # Write the configuration to a YAML file\n",
        "    with open(yaml_path, 'w') as f:  # open target YAML path for writing\n",
        "        yaml.dump(data_config, f)  # serialize the configuration to disk\n",
        "\n",
        "    print(\"YOLO YAML created successfully.\")  # status update for the user\n",
        "\n",
        "    return yaml_path  # return path so caller can pass it to YOLO train\n",
        "\n",
        "def train_yolov8(cfg, train, val, test):  # orchestrate restructuring and invoke Ultralytics training\n",
        "    if not YOLO_AVAILABLE:  # guard if ultralytics isn’t installed\n",
        "        print(\"Ultralytics YOLO not installed; skipping training step.\")  # tell user why training is skipped\n",
        "        return None  # nothing to return in this case\n",
        "\n",
        "    restructure_splits_for_yolo(cfg, train, val, test)  # lay out images/labels into YOLO directory tree\n",
        "    print(\"Data splits to moved to YOLO format\")  # confirmation that data is ready for training\n",
        "\n",
        "    data_yaml = write_yolo_data_yaml(cfg)  # generate data.yaml and get its path\n",
        "\n",
        "    # Ultralytics expects images and labels in the same root; labels use .txt alongside tiles in labels dir (auto-detected)\n",
        "    # To ensure compatibility, symlink or ensure directory\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- keep your imports, Config, utilities, and pipeline code above ---\n",
        "\n",
        "def visualize_samples(cfg, n=12):  # randomly render a few tiles with their labels for a quick QA pass\n",
        "    # Ensure viz dir exists (usually created by cfg.initDirs)\n",
        "    os.makedirs(cfg.VIZ_DIR, exist_ok=True)\n",
        "\n",
        "    # Clean the viz folder first so you only see fresh outputs\n",
        "    for f in os.listdir(cfg.VIZ_DIR):\n",
        "        try:\n",
        "            os.remove(os.path.join(cfg.VIZ_DIR, f))\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: could not remove {f}: {e}\")\n",
        "\n",
        "    img_paths = sorted(glob.glob(os.path.join(cfg.TILES_DIR, \"*.jpg\")))  # all generated tile images\n",
        "    if not img_paths:\n",
        "        print(f\"No images found in {cfg.TILES_DIR}. Did tiling run and save .jpg tiles?\")\n",
        "        return\n",
        "\n",
        "    rng = np.random.default_rng(cfg.SEED)  # seeded RNG for reproducibility\n",
        "    picks = rng.choice(img_paths, size=min(n, len(img_paths)), replace=False)  # pick up to n images\n",
        "    for p in picks:\n",
        "        base = Path(p).stem\n",
        "        lbl = os.path.join(cfg.LABELS_DIR, base + \".txt\")\n",
        "        img = cv2.imread(p)\n",
        "        if img is None:\n",
        "            print(f\"Warning: failed to read image {p}\")\n",
        "            continue\n",
        "        img = img[:, :, ::-1]  # BGR->RGB\n",
        "        drawn = draw_yolo_boxes_on_image(img, lbl)  # overlay boxes if label file exists\n",
        "        out_path = os.path.join(cfg.VIZ_DIR, base + \"_viz.jpg\")\n",
        "        try:\n",
        "            Image.fromarray(drawn).save(out_path, quality=95)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: failed to save {out_path}: {e}\")\n",
        "    print(f\"Saved visualizations to: {cfg.VIZ_DIR}\")"
      ],
      "metadata": {
        "id": "zKqWKRUSDON_"
      },
      "id": "zKqWKRUSDON_",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_name = \"experiment_1\"\n",
        "# ---------- RUN SECTION (execute after the definitions above) ----------\n",
        "cfg = Config(name=exp_name, overwrite=True)\n",
        "\n",
        "# Step 1–2: Tiling + initial pseudo-labels\n",
        "yolo_items = process_imagery_and_generate_labels(cfg)\n",
        "\n",
        "# Quick QA thumbnails\n",
        "visualize_samples(cfg, n=10)\n"
      ],
      "metadata": {
        "id": "Jb90zuTyjij3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ae82f3b5-647e-450f-aa48-e245bdf16cef"
      },
      "id": "Jb90zuTyjij3",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization Successful.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=4, read=5, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7be0587638f0>, 'Connection to maps6.stlouis-mo.gov timed out. (connect timeout=5)')': /arcgis/rest/services/FORESTRY/FORESTRY_TREES/MapServer/0/query\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2273961172.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 1–2: Tiling + initial pseudo-labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0myolo_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_imagery_and_generate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Quick QA thumbnails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3621051368.py\u001b[0m in \u001b[0;36mprocess_imagery_and_generate_labels\u001b[0;34m(cfg, trees_gdf, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 1) Get points once (from caller or cache/service)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrees_gdf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrees_gdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_trees_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Ensure a valid CRS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrees_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2482857674.py\u001b[0m in \u001b[0;36mget_trees_gdf\u001b[0;34m(cfg, cache_name, force_refresh)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Query service robustly (POST + timeout + paging), then convert to GDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     fs_json = query_feature_service(\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mlayer_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1=1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2607895662.py\u001b[0m in \u001b[0;36mquery_feature_service\u001b[0;34m(layer_url, where, out_fields, out_wkid, aoi_envelope_wgs84, page_size, token)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resultRecordCount\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (connect, read)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    869\u001b[0m                 \u001b[0;34m\"Retrying (%r) after connection broken by '%r': %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             )\n\u001b[0;32m--> 871\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    872\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;31m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLSocket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mtls_in_tls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             sock = connection.create_connection(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars = [var for var in cfg.__dict__.keys() if \"DIR\" not in var]\n",
        "dict_result = {var:cfg.__dict__[var] for var in vars}\n",
        "df = pd.DataFrame.from_dict(dict_result)\n",
        "df = df.iloc[[0]]\n",
        "df"
      ],
      "metadata": {
        "id": "PEvgnvGblEed"
      },
      "id": "PEvgnvGblEed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce0ea5b",
      "metadata": {
        "id": "7ce0ea5b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "visualize_samples(cfg,n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e20c915",
      "metadata": {
        "id": "0e20c915"
      },
      "outputs": [],
      "source": [
        "# Step 3: Split\n",
        "train, val, test = split_data(yolo_items, cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0af19ee0",
      "metadata": {
        "id": "0af19ee0"
      },
      "outputs": [],
      "source": [
        "# Step 4: Option A: Train YOLOv8 (object detection baseline)\n",
        "train_yolov8(cfg, train, val, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c146556",
      "metadata": {
        "id": "5c146556"
      },
      "outputs": [],
      "source": [
        "# Optional: Step 4b: DeepForest baseline (uncomment if desired)\n",
        "# if DEEPFOREST_AVAILABLE:\n",
        "#     m = deepforest_main.deepforest()\n",
        "#     m.use_release()\n",
        "#     # DeepForest expects CSV annotations; convert labels if needed.\n",
        "\n",
        "# Step 5: Quick visual checks\n",
        "visualize_samples(cfg,n=10)\n",
        "print(\"Phase 1 completed. Check output/ for tiles, labels, splits, metrics, and visualizations.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_health_report(cfg, list_examples=True, max_examples=8):\n",
        "    import glob\n",
        "    from pathlib import Path\n",
        "\n",
        "    img_paths = sorted(glob.glob(os.path.join(cfg.TILES_DIR, \"*.jpg\")))\n",
        "    lbl_paths = sorted(glob.glob(os.path.join(cfg.LABELS_DIR, \"*.txt\")))\n",
        "\n",
        "    imgs_by_stem = {Path(p).stem: p for p in img_paths}\n",
        "    lbls_by_stem = {Path(p).stem: p for p in lbl_paths}\n",
        "\n",
        "    total_imgs = len(img_paths)\n",
        "    total_lbls = len(lbl_paths)\n",
        "\n",
        "    labeled_imgs, empty_label_imgs, missing_label_imgs = [], [], []\n",
        "    total_boxes = 0\n",
        "\n",
        "    for stem, imgp in imgs_by_stem.items():\n",
        "        lblp = lbls_by_stem.get(stem)\n",
        "        if lblp is None:\n",
        "            missing_label_imgs.append(imgp)\n",
        "            continue\n",
        "        try:\n",
        "            with open(lblp, \"r\") as f:\n",
        "                lines = [ln.strip() for ln in f.readlines()]\n",
        "            valid_lines = []\n",
        "            for ln in lines:\n",
        "                if not ln:\n",
        "                    continue\n",
        "                parts = ln.split()\n",
        "                if len(parts) >= 5:\n",
        "                    try:\n",
        "                        float(parts[1]); float(parts[2]); float(parts[3]); float(parts[4])\n",
        "                        valid_lines.append(ln)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "            if valid_lines:\n",
        "                labeled_imgs.append(imgp)\n",
        "                total_boxes += len(valid_lines)\n",
        "            else:\n",
        "                empty_label_imgs.append(imgp)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: could not read label file for {imgp}: {e}\", flush=True)\n",
        "            empty_label_imgs.append(imgp)\n",
        "\n",
        "    n_labeled = len(labeled_imgs)\n",
        "    n_empty = len(empty_label_imgs)\n",
        "    n_missing = len(missing_label_imgs)\n",
        "    coverage_pct = ( (n_labeled + n_empty) / total_imgs * 100.0 ) if total_imgs else 0.0\n",
        "    labeled_pct  = ( n_labeled / total_imgs * 100.0 ) if total_imgs else 0.0\n",
        "    avg_boxes = (total_boxes / n_labeled) if n_labeled else 0.0\n",
        "\n",
        "    # PRINT (force flush so it shows in Colab)\n",
        "    print(\"\\n=== DATASET HEALTH REPORT ===\", flush=True)\n",
        "    print(f\"Run name:         {cfg.name}\", flush=True)\n",
        "    print(f\"Tiles dir:        {cfg.TILES_DIR}\", flush=True)\n",
        "    print(f\"Labels dir:       {cfg.LABELS_DIR}\\n\", flush=True)\n",
        "\n",
        "    print(f\"Total images:                 {total_imgs}\", flush=True)\n",
        "    print(f\"Total label files:            {total_lbls}\", flush=True)\n",
        "    print(f\"Images with ≥1 box:           {n_labeled}\", flush=True)\n",
        "    print(f\"Images with empty label file: {n_empty}\", flush=True)\n",
        "    print(f\"Images missing label file:    {n_missing}\", flush=True)\n",
        "    print(f\"Image-label coverage:         {coverage_pct:.1f}%\", flush=True)\n",
        "    print(f\"Labeled image rate:           {labeled_pct:.1f}%\", flush=True)\n",
        "    print(f\"Total boxes:                  {total_boxes}\", flush=True)\n",
        "    print(f\"Avg boxes per labeled image:  {avg_boxes:.2f}\", flush=True)\n",
        "\n",
        "    ## OS: Recommendation:\n",
        "    ## Add Model Diagnostics to Parameter Table\n",
        "    df[\"Total images\"] = total_imgs\n",
        "    df[\"Total label files\"] =  total_lbls\n",
        "\n",
        "\n",
        "    if list_examples:\n",
        "        def show_examples(title, items):\n",
        "            if not items:\n",
        "                return\n",
        "            print(f\"\\n{title} (showing up to {max_examples}):\", flush=True)\n",
        "            for p in items[:max_examples]:\n",
        "                print(\"  -\", p, flush=True)\n",
        "\n",
        "        show_examples(\"Examples: images with ≥1 box\", labeled_imgs)\n",
        "        show_examples(\"Examples: images with empty label file\", empty_label_imgs)\n",
        "        show_examples(\"Examples: images missing label file\", missing_label_imgs)\n",
        "\n",
        "    print(\"=== END REPORT ===\\n\", flush=True)\n",
        "\n",
        "    ##TODO:\n",
        "    #df.to_csv(\"some path\")\n",
        "\n",
        "    # Also return a dict you can display or log\n",
        "    return {\n",
        "        \"run\": cfg.name,\n",
        "        \"tiles_dir\": cfg.TILES_DIR,\n",
        "        \"labels_dir\": cfg.LABELS_DIR,\n",
        "        \"total_images\": total_imgs,\n",
        "        \"total_label_files\": total_lbls,\n",
        "        \"images_with_boxes\": n_labeled,\n",
        "        \"images_empty_label\": n_empty,\n",
        "        \"images_missing_label\": n_missing,\n",
        "        \"coverage_pct\": coverage_pct,\n",
        "        \"labeled_pct\": labeled_pct,\n",
        "        \"total_boxes\": total_boxes,\n",
        "        \"avg_boxes_per_labeled\": avg_boxes,\n",
        "    }\n",
        "\n",
        "report = dataset_health_report(cfg)  # <-- this line actually runs & prints\n",
        "report  # also display the returned dict as cell output\n"
      ],
      "metadata": {
        "id": "Od82Q81GPdw5"
      },
      "id": "Od82Q81GPdw5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KKLN8JZLRs2U"
      },
      "id": "KKLN8JZLRs2U",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tree_detection_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}